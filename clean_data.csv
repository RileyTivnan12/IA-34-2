id,department,q1_tool_vendor_name,q2_ purpose,q3_intended_use,q4_context,q5_ training_data,q6_how_it_works,q7_output_data,q8_optimization_accuracy,q9_ optimal_conditions,q10_ performance_decrease_conditions,q11_bias_testing,q12 _reported_issues,q13_testing_conditions,q14_incident_monitoring,q15_human_oversight,q16_data_reuse_for_training,q17_users,q18_public_or_worker_impact,q19_accessibility,q20_job_impact,q21_why_the_city_needs_it,q22_risks_and_mitigations,data_as_of,data_loaded_at
DPH-Evolv Express concealed weapons detection,DPH,Evolv Express concealed weapons detection,"Evolv Express is a next-generation, AI-powered concealed weapons detection system designed to enhance physical security in high-traffic public venues by enabling fast, frictionless screening without requiring individuals to stop or empty their pockets.",Concealed weapons (guns and knives) detection at ZSFG entrances,"The weapons detection system is a part of the workplace safety program to assist in identifying and minimizing workplace safety risks. Based on the the ZSFG annual security risk assessment, the lack of weapons detection is a contributing fractor for patients entering the ZSFG hospital/clinics armed with sharp edged weapons and replica firearms.   Based on the increase in workplace violence incidents in healthcare facilities, California Assembly Bill 2975 requires that hospitals implement a weapons detection screening policy and use weapons detection devices at specific entrances.","According to the Evolv website, the ""AI model has been trained on nearly 50,000 object scans, including multiple types of firearms along with everyday items that people carry in their pockets or bags.""","It combines advanced sensor technology, real-time computing, and machine learning to accurately detect threats while minimizing false alarms and congestion at entry points.","Weapon signatures and images collected on site are referred to as ‘scan data.’ Besides the immediate application of the scan data to detect a weapon and the person carrying the weapon, Evolv performs no further processing of scan data – as in training models or analytics thereof. In other words, Evolv does not ‘harvest’ production data from deployment sites to develop AI models. The video retaining for 30 days and then is recorded over.","Internally, Express uses machine learning models to detect weapon signatures from sensor information gathered from visitors in real time. The sensory information gathered here refers to electromagnetic sensors and visual cameras. Weapon signatures and images collected on site are referred to as ‘scan data.’ Evolv uses the scan data collected from visitors to identify the presence of weapon(s) carried on their person. The decision here is the determination of the presence of a weapon. Performance metrics will be established and monitored quarterly by the Environment of Care Committee. The metrics will include an 85% threshold measurement, 98% target, and a 99% stretch measurement.   The performance metrics will include:  Total Number of monthly weapons alert events to deterimine Cost to Value based on the average recovery expenses per shooting victim.   Number of false positive alerts by type.  Time to resolve alert events compared to the industry standard thirty-second baseline.  Number of alerts requiring law enforcement intervention. Number of reports of weapons discovered within the protected area.","Evolv Express systems must be placed in appropriate locations, away from fixed and moving metal.  Evolv will advise SFPDH staff on appropriate operating conditions to optimize detection performance.","If the Evolv Express system is not placed in appropriate locations away from fixed and moving metal, performance and accuracy would decrease. For this reason, Evolv will advise SFPDH staff on appropriate operating conditions to optimize detection performance.",Use of Evolv Express does not impact equity of care or experience. The system helps detect weapons only without a knowledge of the individuals responsible for generating weapon alerts.,Performance metrics will be established and monitored quarterly by the Environment of Care Committee. Use of Evolv Express does not impact equity of care or experience. The system helps detect weapons only without a knowledge of the individuals responsible for generating weapon alerts.,"In addition to healthcare, the devices are used for sporting events, the entertainment industry, museums and office settings.",Minimizing false positives and false negatives in threat detection are the objectives of Express’s underlying ML algorithms. Evolv internally qualifies detection accuracy with extensive regression at every release & also seeks active feedback from customers on noted detection inaccuracies. This feedback is used to improve the models and the algorithms.,"Evolv system will alert security staff of the possible presence of a concealed weapon, but staff are responsible for investigating the alert and making a final security determination.","DPH does not allow personally identifiable information to be retained by outside vendors. Weapon signatures and images collected on site are referred to as ‘scan data.’ Besides the immediate application of the scan data to detect a weapon and the person carrying the weapon, Evolv performs no further processing of scan data – as in training models or analytics thereof. In other words, Evolv does not ‘harvest’ production data from deployment sites to develop AI models. The video retaining for 30 days and then is recorded over.","Intended users are the San Francisco Sheriff’s Office, SFSO the primary security services provider for the San Francisco Department of Public Health. Users will not be directly interacting with the AI/ML capabilities of Evolv Express. Evolv Express embeds within its software ML algorithms and pre-trained models to differentiate between weapons and benign objects, for SFSO personnel to identify potential threats and threatening visitors on their site.  Evolv Express will not be used in clinical operations as applicable to health care.","ZSFG has developed multiple workplace safety initiatives communications, including posting signs at entrances translated into all threshold languages informing visitors they will be screened for weapons. Evolv Express is a weapon detection system meant for deployment at facility entrances with high traffic. This system helps detect weapons only without a knowledge of the individuals responsible for generating weapon alerts.","For all SFDPH users who require assistive technologies for ADA reasons, DPH will follow standard policies and procedures for accommodation.",No.,"The weapons detection system is a part of the workplace safety program to assist in identifying and minimizing workplace safety risks. Based on the the ZSFG annual security risk assessment, the lack of weapons detection is a contributing fractor for patients entering the ZSFG hospital/clinics armed with sharp edged weapons and replica firearms.   Based on the increase in workplace violence incidents in healthcare facilities, California Assembly Bill 2975 requires that hospitals implement a weapons detection screening policy and use weapons detection devices at specific entrances.   Based on the FBI 2023 Active Shooter report, 42% of active shooter events that occured in healthcare facilities, the shooter had a known connection with the location of being a current or former employee, or applicant.","The potential “harms” from a false positive detection (i.e., alert on a benign object) would result in additional steps to resolve the alert, resulting in delays or a false negative detection (miss alerting on a threat object) could result in an increased risk of violence occurring within the protected area.",2025/07/15,2025/07/18
DPH-Ischemaview Rapid AI,DPH,Ischemaview Rapid AI,"Rapid AI is used to identify and guide treatment for ischemic strokes in near real time by analyzing CT/MRI scans. It helps clinicians decide whether urgent interventions like thrombolysis are required, potentially improving patient outcomes and reducing time spent in the ED.","The tool is intended for any individual (inpatients or ED arrivals) displaying stroke symptoms, a group that includes diverse populations at elevated risk. Primary users include neurologists, ED clinicians, and quality-improvement teams responsible for detecting and treating strokes promptly.","Rapid AI integrates into clinical stroke workflows by processing the imaging scans as soon as they are obtained. Clinicians then interpret the results to decide on potential interventions, such as thrombolytics or embolectomy.","The system is a clinically oriented radiological imaging platform that leverages machine learning, both Convolutional Neural Networks (CNNs) and Random Forest techniques, to aid in diagnosing conditions like ischemic stroke, intracranial hemorrhage, and pulmonary embolism. Designed to process imaging data from CT and MRI scanners, the AI generates parametric outputs to assist physicians during triage and diagnosis. Data used for training and validation are sourced globally (~50% U.S., ~50% international), de-identified per hospital policies, and reviewed by clinical experts. A strict data separation policy ensures that validation datasets—blinded and sourced from at least three sites—are independent of development data. The AI is static once validated and regulatory-approved, with changes requiring re-approval. Performance metrics include sensitivity, specificity, accuracy, and time-to-diagnosis, aiming to reduce diagnostic variability and interpretation time while supporting faster and more accurate clinical decisions. APIs integrate with hospital systems like PACS (the diagnostic imaging data system)  to streamline workflow. Ethical principles—including data privacy, consent, fairness, and transparency—are upheld in accordance with the HITRUST AI Assurance framework.","Rapid AI automatically processes CT or MRI perfusion data to highlight significant areas of ischemia (no bloodflow or ""dead"" brain tissue) and penumbra (low bloodflow and potentially salvegable brain tissue) . The tool curates the resulting analysis and speeds up evaluation by the neurological or interventional radiology team.","Rapid AI generates user-friendly scans highlighting areas of no bloodflow and low bloodflow in the brain. The output appears within minutes, showing ratio calculations (e.g., >1.7 suggests immediate intervention) that help clinicians assess stroke severity and the need for emergent treatment.","Rapid AI is primarily aimed at reducing the time from patient arrival to administration of clot-busting drugs and/or mechanical thrombectomy. The model is FDA-cleared, having undergone clinical validation to ensure sufficient accuracy in identifying candidates for urgent stroke intervention.",Rapid AI will not function if imaging data is missing or incomplete.,"If the system encounters incomplete or poor-quality imaging data, the model might fail to generate actionable results. Any software changes require FDA clearance.","The software’s developers state that the data used for training encompassed diverse patient demographics, aiming to reduce bias in performance across different subpopulations.","Clinicians can discuss or report any concerns, inaccuracies, or perceived bias in the monthly peer-review forum. Additionally, known problems can be escalated directly to RapidAI’s support team.","Rapid AI has undergone validation in multiple real-world clinical settings, with peer-reviewed studies and post-marketing data available at the vendor’s website.","Adverse events or unintended outcomes are raised in recurring stroke program meetings and neurovascular peer reviews. Oversight is also provided by departmental compliance and privacy officers, ensuring any incidents are analyzed and addressed.","Clinicians ultimately decide on diagnosing and treating strokes, with the Stroke Program Coordinator overseeing data and metrics. The AI provides scan interpretations that require final human judgment and accountability in all treatment decisions.",DPH does not allow personally identifiable information (PII) to be retained by proprietary or third-party vendor systems.,"Individuals presenting with stroke symptoms come from diverse communities, often underrepresented groups at higher stroke risk. Clinical staff—especially neurologists and ED clinicians—interact with the system daily to expedite stroke care.","The use of Rapid AI exclusively affects stroke patients and the teams managing their care. Other patients or service lines are not directly impacted, and there are no known secondary effects on public access or rights.","For any SFDPH staff requiring assistive technologies, standard policies for ADA accommodation apply. The Rapid AI interface usage would follow typical hospital accessibility protocols.",This technology is not expected to replace any jobs or impact employment conditions.,"Maintaining a Joint Commission stroke certification is vital for ensuring a high standard of stroke care and for receiving EMS stroke referrals (and associated revenue). Rapid AI facilitates quicker diagnostic decisions, helping SFDPH meet time-to-treatment benchmarks.","Potential risks center on incomplete imaging data or overreliance on AI results. However, the technology is FDA-cleared. Ongoing peer-review meetings and stroke program oversight help mitigate and manage any unintended consequences.",2025/07/15,2025/07/18
DPH-Mirai,DPH,Mirai,"Mirai is an AI tool that identifies high-risk patients from screening mammograms for review by a human radiologist, aiming to speed up results release and diagnostic follow-up. By classifying the top 10% of mammograms that have elevated risk, the model helps prioritize same-day or faster diagnostic evaluations, reducing delays in breast cancer detection.","The tool is intended for women age 30 and older receiving screening mammograms at ZSFG. Radiologists use Mirai’s outputs to determine priority cases, and a research coordinator supports the workflow and engages with the clinical team.","Mirai is integrated into existing mammography workflows but flags high-risk scans in real time. This allows same-day or expedited diagnostic follow-ups for these high-risk cases, reducing the typical wait time.","Mirai was trained on mammograms from a large, diverse dataset subsequently validated across hospitals globally. In real-world use, it uses the standard images obtained for a screening mammogram exam. These images are inputted into Mirai’s deep learning architecture to generate a breast cancer risk score.","Mirai uses deep learning to transform each mammogram view into a vector, aggregates them, and predicts a risk score for breast cancer. Developed by a local researcher, the model was validated globally to ensure robust, consistent performance.",The model instantly generates a risk score/percentile for each completed mammogram. This information helps radiologists identify the highest-risk 10% of patients for possible same-day diagnostic evaluation.,"Mirai aims to shorten wait times for high-risk patients from days/weeks to same-day evaluations. The model has a reported AUC of 0.78, indicating moderate accuracy, with specificity above 90%. Mammogram assessment and, if necessary, diagnostic work-up will follow standard practice.","Mirai relies on standard four-view mammogram data. Because these views are mandatory for screening, the model can perform optimally as long as complete images are provided.","Performance may degrade if the model’s predictions drift and too many mammograms are labeled ""high-risk"". If it flags more than 20% of patients during a 10-day period, the team will stop using the tool to investigate possible inaccuracy or drift.","The model has been evaluated across several institutions to check for bias in different demographic subgroups. Further prospective analysis at ZSFG will monitor equity and fairness, ensuring no group experiences poorer accuracy.","Feedback channels primarily include the research coordinator and investigators, who closely track outcomes. Concerns or evidence of bias can be reported during study monitoring, leading to a pause or recalibration of the model if necessary.","Mirai has undergone extensive retrospective validation in peer-reviewed studies. At ZSFG, it will be used in a controlled research setting and carefully observed for any changes or unexpected behaviors.","The team will run this pilot in a limited capacity (average one day per week) and track any unforeseen negative impacts. If high false-positive rates or other issues arise, they will pause or deactivate the tool pending an investigation.","Clinicians continue reading mammograms as usual, while a research coordinator manages the AI risk output. The investigators and sponsor oversee performance metrics, ensuring that human judgment remains integral to final decisions on patient care.",DPH does not allow personally identifiable information (PII) to be retained by proprietary or third-party vendor systems.,"This includes women 30+ coming for mammograms at ZSFG, along with radiologists, technologists, and the research coordinator who integrates AI outputs into the workflow.","Since only select high-risk patients receive expedited reads, other patients remain on standard protocols. Extra diagnostic slots ensure that prioritizing high-risk patients does not limit access for the broader patient population.","For SFDPH staff requiring assistive technologies for ADA reasons, DPH will follow standard policies and procedures for accommodation.","There is no indication of staff replacement. Mirai’s risk scoring complements the existing workflow, with radiologists still interpreting images and a research coordinator managing study procedures.","By offering faster diagnostic imaging for high-risk patients, Mirai promotes patient safety and care efficiency. It also helps reduce follow-up delays, meeting SFDPH’s goals for timely, equitable healthcare.","Potential risks include labeling too many patients as “high-risk” or failing to identify high-risk cases. The research team monitors false-positive and detection rates daily, ensures data privacy protections, and obtains explicit patient consent for study participation and same-day mammogram assessments.",2025/07/15,2025/07/18
DPH-TalView,DPH,TalView,"TalView’s AI proctoring tool is designed to monitor remote examinations by flagging potentially suspicious behaviors, thereby supporting a fair and consistent assessment process. It leverages a supervised machine learning pipeline that uses historical, de-identified exam session data to flag behaviors needing further human evaluation.","The tool is intended for use by HR and proctoring teams to evaluate candidate behavior during remote examinations. It operates both in a live and post-exam review mode, ensuring that flagged behaviors are carefully vetted before any decision is made.",The technology is deployed in the context of remote testing for job candidates. It is used during online assessments where a live proctor or a post-exam reviewer examines generated reports to validate any questionable behaviors before any action is taken.,"The model is trained on extensive, anonymized, and consented data drawn from a large customer base—including educational institutions, employers, and licensing bodies—to annotate and classify behavioral events during exams. This training enables the system to effectively generate AI proctoring flags for review.","TalView operates by capturing video, audio, and screen activity during exam sessions. It uses an ensemble of computer vision, audio analysis, and behavioral event classifiers—trained on annotated historical data—to generate flags that indicate suspicious activities. These AI-generated alerts are then validated by human proctors.","During each exam, the system generates detailed proctoring reports that include time-stamped AI flags, video segments, and notes provided by human proctors. These outputs serve as a comprehensive review mechanism for candidate behavior.","The technology is optimized to identify and flag suspicious behaviors during remote testing. Internal and customer studies indicate that TalView’s system can detect suspicious activities 6–10 times more frequently than conventional methods, with accuracy levels ranging from 85% to 92%, while all alerts require human confirmation.","For optimal performance, the web-based tool requires a standard computer setup with a webcam, speakers, and a microphone. No additional hardware or specialized conditions are needed for its operation during remote exams. It is the same technical requirement for making a video call on Zoom or MS Teams.","While the system is designed for high accuracy, its performance may be affected by suboptimal input quality—for instance, poor video or audio conditions. However, mandatory human review of all AI-generated flags helps mitigate any potential decrease in accuracy.",Bias testing for equitable performance across diverse groups is not explicitly documented in the current submission.,The intake does not specify a process for reporting bias or inaccuracies; no designated feedback channel is described in the submitted documentation.,"The technology has been developed and tested using a large volume of de-identified proctoring session data from diverse organizations. Controlled internal studies and customer deployments have informed its development, though the evaluations have not been published in peer-reviewed studies.",Adverse incidents are managed through a structured review process: every AI-generated flag is critically examined by a human proctor before any action is taken. This oversight ensures that any unintended incidents are promptly identified and managed according to established consistent protocols.,"The system is implemented with robust human oversight. In both live and recorded review processes, trained human proctors are responsible for validating all flagged behaviors before any decisions or actions are taken.",DPH does not allow personally identifiable information (PII) to be retained by proprietary or third-party vendor systems.,The technology interacts primarily with job candidates undergoing remote assessments and the HR and proctoring teams responsible for reviewing the sessions. Affected users are informed and consent is obtained as part of the online testing registration process.,"While the system generates AI flags that guide decision-making, no candidate will be adversely affected without thorough human review. This oversight is essential to prevent any inadvertent impact on an individual’s opportunities or rights during the selection process.","For users requiring assistive technologies, the system adheres to established SFDPH policies and procedures. Standard accommodations will be provided to ensure equitable access for all users.",The technology is not expected to replace any city jobs or alter the working conditions of City employees; it is implemented to support and enhance current human-led processes.,"Implementing TalView’s AI proctoring system is important because it provides an objective and efficient framework for monitoring remote examinations. This helps maintain fairness, consistency, and integrity in candidate assessments while supporting the overall operational goals of SFDPH.","The primary risk is the potential for non-problematic behavior to be flagged erroneously, which could affect a candidate’s opportunity. To mitigate this, every AI-generated flag is reviewed by a human proctor before any action is taken, ensuring that only valid concerns are acted upon.",2025/07/15,2025/07/18
DPH-TransMed Inspirata Epath,DPH,TransMed Inspirata Epath,This tool is a rule-based system that automates the detection of cancer-related terms in pathology reports and forwards the relevant findings to the state and hospital for further processing.,"The technology is intended to process diagnostic and treatment information for cancer patients. It is primarily used by oncology data specialists and other health information management staff, the pathology department, and compliance officers.","Within the existing pathology reporting workflow, users rely on the tool’s output to report new cancer cases, ensuring timely identification and reporting without requiring major changes to current processes.","The tool uses rule-based natural language processing applied to HL7 pathology report text. These rules, originally developed under state requirements and updated regularly, form the basis for identifying cancer terminology.","This AI engine employs rule-based natural language processing to review pathology results in HL7 messages. It checks text for cancer-specific terminology, updating those rules annually to meet state and national guidelines. Implemented since 2013, it integrates with hospital systems to streamline automated reporting of cancer cases.",The system generates real-time alerts or flags for pathology reports containing terms indicative of cancer.,"This technology aims to identify and capture all cancer cases as indicated by pathology reports, maximizing the completeness and timeliness of reporting. It has demonstrated strong accuracy, with a reported sensitivity of 1.0, specificity of 0.976, and overall efficiency of 0.980.","As long as the system receives pathology data and the underlying rules continue to be updated, the system will continue to perform optimally.","If the software encounters pathologist reports containing terms not recognized by the existing rules or inaccurate data, it may fail to capture some cancer cases. Ongoing updates to the rule base and validation by Health Information Management help mitigate these issues.","The technology focuses solely on detecting specific cancer-related keywords within pathology data. Because it does not process patient demographics or protected characteristics, the potential for biased performance based on patient identity is minimal.","Users can compare the tool’s flagged cases against Epic reports, and if discrepancies arise or they suspect inaccuracies, they may open a support ticket with Inspirata via email.","It has been used for many years across multiple state registries and healthcare facilities under the supervision of the National Cancer Institute, offering robust real-world validation.","Adverse events or unintended consequences are mitigated by encryption, state-overseen reporting requirements, and review by DPH Health Information Management staff, who validate potentially flagged cancer cases before final submission.","Human oversight occurs throughout the process, as oncology data specialists and Health Information Management staff review flagged pathology reports. Accountability lies with the cancer registry team, who can verify and validate flagged cases.",DPH does not allow personally identifiable information (PII) to be retained by proprietary or third-party vendor systems.,"The primary patient community includes those with cancer diagnoses whose pathology results need reporting. Those who interact directly with the tool include oncology data specialists, pathology staff, compliance officers, and Health Information Management personnel.","The tool’s core function is to ensure accurate and timely cancer case reporting, which does not appear to change patients’ rights or access to resources.","For all SFDPH users who require assistive technologies for ADA reasons, DPH will follow standard policies and procedures for accommodation.",This technology is not expected to replace any jobs or impact the employment and/or working conditions of City workers.,"The tool supports SFDPH objectives by improving patient safety, data quality, and operational efficiency for cancer case reporting. It reduces human error, ensures compliance with state mandates, and conserves resources that would otherwise be required for manual data review.","The main risks involve missed or inaccurate cancer case reporting. To mitigate this, DPH Health Information Management staff validate flagged reports, and the software receives regular updates aligned with state requirements. Data security measures are also in place, following California Assembly Bill AB2325 for mandated electronic reporting.",2025/07/15,2025/07/18
DPH-ZSFG 30 Day Unplanned Heart Failure Readmission Risk Model,DPH,ZSFG 30 Day Unplanned Heart Failure Readmission Risk Model,"This tool predicts 30-day unplanned readmission risk for patients with heart failure, helping providers identify and proactively support high-risk patients. It is a Gradient Boosted Tree model that uses electronic health record data to generate real-time risk assessments and integrate them into clinical workflows.","The model is meant for inpatient and outpatient healthcare providers—such as physicians, nurses, case managers, and heart failure specialists—at ZSFG and within the San Francisco Department of Public Health. It augments decision-making by informing clinicians about patient readmission risk, without replacing existing staff.","The model is incorporated into the hospital’s EHR-based workflow. Each day, it calculates risk scores for heart failure patients, providing real-time support to clinicians through a decision-support interface in the EHR.","This model was trained and validated on EHR data from heart failure patients at ZSFG, covering tens of thousands of encounters. Its 42 predictive inputs include lab results, prior emergency visits, and other clinical indicators that help identify each patient’s risk of readmission.","The core of this technology is a Gradient Boosted Tree model that processes up to 42 variables from patient records, automatically identifying patterns that predict a high risk of readmission. It is fully integrated into ZSFG’s EHR environment via Epic’s Nebula cloud.",The model provides a daily estimated probability that a patient will be readmitted within 30 days. A patient is labeled as “high risk” if the predicted readmission likelihood surpasses 12%.,"The technology optimizes for fewer 30-day unplanned heart failure readmissions and better equity of care. Its reported accuracy includes an AUC of 0.73, with relatively consistent performance across demographic subgroups. The overarching goal is to reduce readmission rates and improve outcomes for high-risk patients.","Adequate IT support, data protection, and regular monitoring of infrastructure are essential so that the model can accurately generate risk predictions.","The model’s performance may decline if its predictive variables, clinical data sources, or care patterns significantly change over time. Inaccurate risk predictions can lead to missed patient referrals (false negatives) or unnecessary prioritizations (false positives). Ongoing performance monitoring helps detect and address any deterioration in accuracy.",The developers examined model performance by subgroup and intentionally excluded race or ethnicity variables in training to reduce bias. They report that the model performs similarly across different demographic groups.,"The PROSPECT lab and clinical stakeholders hold monthly meetings to review model performance, gather user feedback, and address any concerns. They also perform annual analyses of predictive accuracy; significant drops in performance or bias trigger additional investigation and possible revisions to the model.",The model was tested on a historically diverse dataset of heart failure patients from 2019 to 2024 at ZSFG. Supplementary documents about the model’s development and performance have been shared with relevant SFDPH personnel.,"Adverse incidents, inaccuracies, or other issues are identified through monthly check-ins, structured surveys, and ongoing performance assessments. Clinicians can refer to a model card for guidance, and the team regularly compares predicted outcomes with real patient data.","Providers receive ongoing training to integrate the model’s predictions into standard care practices. Although the model automates risk stratification, clinicians remain responsible for evaluating and acting on the recommendations.",DPH does not allow personally identifiable information to be retained by outside vendors. The model is developed and used internally; no external or proprietary third-party systems are involved.,The primary audience includes inpatient and outpatient care teams at ZSFG and the broader SFDPH heart failure patient community.,"The technology does not limit or deny care to any patient. Instead, it prioritizes higher-risk individuals for earlier specialty referrals, potentially improving equity in access to timely interventions.","Because the model is accessed through the Epic EHR interface, existing Epic features for accessibility and assistive technologies apply. Its usability for diverse providers parallels the standard EHR environment.","The model is designed to complement clinical work rather than replace it, offering recommendations that free up time for complex patient care without displacing staff roles.","Reducing unplanned readmissions for heart failure patients not only improves patient outcomes but also helps sustain financial resources in a safety net system. By addressing gaps in care and standardizing interventions, the City can maintain high-quality services for its most vulnerable populations.","Potential risks include overlooking high-risk patients (false negatives) or prioritizing low-risk patients (false positives). The team mitigates these risks by monitoring the model’s performance monthly, gathering feedback from clinicians, and providing oversight to ensure that no patient is denied care due to AI-based recommendations.",2025/07/15,2025/07/18
SFPUC-Anzu Raptor Drone,SFPUC,Anzu Raptor Drone,"Drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.","Drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.",The ANZU Raptor Drone is intended to be used for aerial photography and visual documentation.,"The Anzu Raptor drone’s AI is designed to support autonomous flight and high-resolution data collection through integration with platforms like Aloft Air Control and Drone link. The company hasn’t disclosed specific training methods,  AI likely relies on sensor fusion, rule-based automation, and pre-trained vision models for navigation and mission planning.","The Anzu Raptor Drone works by combining advanced hardware with secure, U.S.-based software to deliver high-precision aerial data for mapping, inspections, and public safety missions. The Raptor features a 20MP wide-angle camera and a 12MP telephoto lens with up to 56x hybrid zoom, omnidirectional obstacle avoidance, and a 45-minute flight time.
* Transmission protocols: The Raptor T leverages NDAA-compliant protocols like AES encryption and adaptive bitrate streaming, empowering you to maintain secure, high-fidelity links for unrestricted operations.
* Signal interference resilience: Built-in frequency hopping counters environmental noise, analytically reducing packet loss by up to 90%, so you can operate freely in urban or obstructed areas.
* Range and stability analysis: At 7 km, it outperforms standard Wi-Fi by integrating dual-band support, offering analytical advantages in long-distance scenarios for enhanced autonomy.","Anzu Raptor drones generate a comprehensive range of flight, imaging, and operational data designed for secure, U.S.-based enterprise and government use. These drones prioritize data sovereignty and local storage, while providing high-resolution aerial intelligence for mapping, inspections, and documentation.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics. Predictive analytics integrate ethical safeguards, ensuring you maintain control and accountability in thermal imaging scenarios.","Temperature Range: Operates best between -10°C to 40°C (14°F to 104°F)
Wind Resistance: Can handle winds up to 26 mph (12 m/s), but for precision tasks like mapping or inspections, calmer conditions are ideal
Weather: The drone does not have an IP rating, so it’s not waterproof. Avoid rain, snow, or high humidity
* Lighting: Performs well in low-light conditions thanks to its Smart Low-Light Photo mode, but direct sunlight or glare can affect image quality
* Transmission Range: Up to 15 km (9.3 miles) in open areas with minimal interference
* Frequency Bands: Uses 2.4 GHz and 5.8 GHz, with automatic channel switching for optimal signal strength
* GNSS Availability: For RTK precision, ensure strong GPS signal—avoid urban canyons or dense forests that may block satellites","Keep sensors clean and unobstructed to ensure omnidirectional obstacle detection functions properly
Ensure the gimbal and camera are properly secured and balanced to avoid drift or vibration
Keep firmware current for optimal performance and security enhancements.","No, there is no publicly available information indicating that Anzu Robotics has conducted or published tests specifically aimed at identifying potential biases—such as those based on race, gender, or other demographic factors—in the AI systems of its Raptor drone series. The company's publicly shared documentation and resources primarily focus on the drones' technical specifications, imaging capabilities, and operational performance in various environmental conditions.","General inquiries or to report bias, contact info@anzurobotics.com","The drone has been deployed in construction site surveys, agricultural field mapping, and infrastructure inspections.  Its RTK-enabled positioning and mechanical shutter were tested for photogrammetry accuracy without the need for ground control points (GCPs).","Safe Air Raptor System: Developed by Para Zero, this autonomous safety system continuously monitors flight parameters (e.g., altitude, pitch, roll, descent rate) for anomalies. If a critical failure is detected—like motor loss or freefall—it:
*Terminates flight by stopping the rotors
*Deploys a parachute within milliseconds
*Controls descent to minimize impact energy2

Omnidirectional Obstacle Avoidance: Vision sensors on all sides detect and respond to potential collisions in real time, reducing the risk of crashes.

*Return-to-Home (RTH) Logic: In the event of signal loss or low battery, the drone automatically initiates a safe return to its takeoff point, using obstacle avoidance to navigate back
*Issues real-time alerts for airspace conflicts, system errors, or environmental hazards
*Logs all flight data for post-incident analysis and compliance auditing
*Beacon & Auxiliary Lighting: Enhances visibility during low-light operations and helps ground teams visually track the drone during emergencies.
*Black Box Logging: The Safe Air Raptor system includes a flight data recorder that stores incident logs, retrievable via desktop software for investigation and reporting",High level of human-in-the-loop oversight. Operated internally with human control and pre-programmed flight paths; staff review collected data.,"No Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.","Drones are internally managed and operated by trained staff and contractors for purposes such as inspections, monitoring, and project documentation. Individuals who interact with this technology include agency personnel, nearby residents, and community members who may view drone imagery through public updates or reports.",SFPUC drone data can improve public rights by enhancing how infrastructure services are monitored and delivered.,Drones used by SFPUC do not have direct user interfaces designed for public interaction.,No jobs will be eliminated.,"Drones are a critical tool for SFPUC because they enable safe, efficient, and cost-effective inspection, monitoring, and visualization of infrastructure and environmental conditions, especially in areas that are difficult, hazardous, or expensive to access by ground.","Anzu Raptor drones pose risks such as data breaches, flight failures, regulatory issues, and human error, mitigated through U.S.-based secure systems, safety features, compliance tools, and operator training. Human-in-the-loop mitigates risk.",2025/07/15,2025/07/18
SFPUC-ArcGIS,SFPUC,ArcGIS,"ArcGIS helps organizations understand patterns, relationships, and trends through spatial analysis.","The intended use of ArcGIS is to support the collection, analysis, visualization, and sharing of geographic data for informed decision-making.","Deployed for mapping, program and asset management, infrastructure inspection, public engagement, or data collection.","Most tools are trained on public datasets, proprietary data, or user-generated content, depending on the development practices.","ArcGIS (developed by Esri) is a powerful Geographic Information System (GIS) platform that enables users to collect, analyze, visualize, and share spatial (location-based) data.","ArcGIS, a geographic information system (GIS) platform by Esri, generates a wide variety of spatial and non-spatial data through mapping, analysis, field collection, and integration workflows.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","GNSS Availability: For RTK precision, ensure strong GPS signal—avoid urban canyons or dense forests that may block satellites.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Errors or performance issues reported internally to GIS team or via Esri support at support.esri.com.,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"ArcGIS does not include a built-in automated system to detect or report adverse incidents, but users monitors system issues, data errors, and user concerns through internal workflows and support channels.","Medium level of human-in-the-loop. Data layers and dashboards are created by analysts, but some mapping and field tools operate semi-autonomously.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",General public and city departments utilize ArcGIS maps that are published to websites for the community to use as a mapping tool for visual aids.,"ArcGIS supports SFPUC’s ability to map, analyze, and share spatial data that informs public decisions about infrastructure, environmental monitoring, and community services.","ArcGIS (by Esri) provides partial accessibility support and is compatible with many commonly used assistive technologies, including screen readers, keyboard navigation, and high-contrast displays.",No jobs will be eliminated.,"ArcGIS is a core geospatial platform used by SFPUC to manage, analyze, and visualize infrastructure, environmental, and operational data across the City’s water, power, and sewer systems.","ArcGIS risks involve the presentation of outdated or inaccessible spatial data, which SFPUC mitigates by maintaining regular data updates, adhering to accessibility best practices, and offering alternative formats for critical map-based information.",2025/07/15,2025/07/18
"SFPUC-DJI Drones (9)
(Mavric 2 Pro (QTY 2), Matrice 360, Matrice 300 (QTY 2), Mavic Thermal, Mavic 3 Pro, Matrice 600, Phantom 4 Pro)",SFPUC,"DJI Drones (9)
(Mavric 2 Pro (QTY 2), Matrice 360, Matrice 300 (QTY 2), Mavic Thermal, Mavic 3 Pro, Matrice 600, Phantom 4 Pro)","DJI drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.","DJI drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.","Drones are primarily used for aerial photography to support documentation, communication, and project monitoring activities. This includes capturing high-resolution images and video footage of construction sites, infrastructure assets, and environmental landscapes. The imagery is used to enhance public outreach, track project progress, support internal planning, and visually document conditions in areas that are difficult or unsafe to access by ground.","In the DJI drone ecosystem, AI training is enabled through developer Software Development Kits (SDKs) and educational platforms that allow users to collect data, train custom models (e.g., for object detection), and deploy them directly to drones for real-time processing, with a focus on flexibility, privacy, and edge computing.","Range and stability analysis: At 7 km, it outperforms standard Wi-Fi by integrating dual-band support, offering analytical advantages in long-distance scenarios for enhanced autonomy.","DJI drones generate a wide range of flight, visual, and sensor data, which is used for aerial imaging, navigation, analysis, and compliance. The data is captured during operation and can be stored on the drone, the controller, or transmitted to external devices or cloud platforms depending on configuration.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Tools perform best with reliable data, network access, vendor configuration support, and operator training.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Report issues to DJI support at www.dji.com/support.,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"DJI drones themselves do not include an automated adverse incident reporting system, but users actively monitor drone operations and document any anomalies or safety concerns.",High level of human-in-the-loop oversight. Flights are manually piloted or semi-autonomous with required human control and FAA compliance.,"No. In the DJI drone ecosystem, AI training is enabled through developer Software Development Kits (SDKs) and educational platforms that allow users to collect data, train custom models (e.g., for object detection), and deploy them directly to drones for real-time processing, with a focus on flexibility, privacy, and edge computing. SFPUC is not using data to train the drone.","Drones are internally managed and operated by trained staff and contractors for purposes such as inspections, monitoring, and project documentation. Individuals who interact with this technology include agency personnel, nearby residents, and community members who may view drone imagery through public updates or reports.",SFPUC drone data can improve public rights by enhancing how infrastructure services are monitored and delivered.,Drones used by SFPUC do not have direct user interfaces designed for public interaction.,No jobs will be eliminated.,"Drones are a critical tool for SFPUC because they enable safe, efficient, and cost-effective inspection, monitoring, and visualization of infrastructure and environmental conditions, especially in areas that are difficult, hazardous, or expensive to access by ground.","DJI drones pose risks such as data privacy concerns, equipment failure, and limited accessibility of collected imagery, which SFPUC mitigates through encrypted data storage, trained pilot oversight, FAA-compliant operations, and providing information in accessible formats when shared publicly.",2025/07/15,2025/07/18
"SFPUC-Facebook 
(Meta)",SFPUC,"Facebook 
(Meta)","Facebook as a real-time communication tool to increase transparency, share educational content, and foster civic engagement.","Facebook is intended to be used for public outreach, information sharing, and community engagement.","Facebook serves as a real-time communication tool to increase transparency, share educational content, and foster civic engagement.","Facebook uses a combination of sources are used for training, information that is publicly available online and licensed information. Facebook also uses information shared on Meta Products. This information could be things like posts or photos and their captions. Facebook does not use the content of your private messages with friends and family to train our AIs unless you or someone in the chat chooses to share those messages with Facebook AIs. For AI features that use , Meta cannot read or access the private messages you have shared.","Facebook is a social networking platform powered by a combination of databases, machine learning algorithms, content delivery networks (CDNs), and user interface systems that work together to deliver personalized experiences in real time.","Facebook generates a wide range of data based on user activity, content sharing, and platform interactions.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Weather: The drone does not have an IP rating, so it’s not waterproof. Avoid rain, snow, or high humidity.",Keep firmware current for optimal performance and security enhancements,"Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Go to https://www.facebook.com/help to Report a Problem,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,Facebook uses a combination of automated detection systems and human moderation to monitor for adverse incidents.,"High level of human-in-the-loop oversight. All posts and replies are authored, reviewed, and managed by human staff.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",People of all demographics use Facebook but use varies by age of the population.,"Information shared by SFPUC through Facebook may directly influence the public’s awareness of and access to critical resources such as emergency alerts, service disruptions, and community programs.","Facebook supports accessibility for people with diverse abilities by integrating with widely used assistive technologies such as screen readers, keyboard navigation, and voice control tools. The platform includes features like automatic alt text for images, high-contrast display modes, and customizable captioning for videos.",No jobs will be eliminated.,"Facebook is a vital communication tool for SFPUC because it enables the agency to reach a wide, diverse public audience with real-time updates about water, power, and sewer services, emergencies, and community programs.","Facebook risks include algorithm-driven visibility gaps, misinformation, and accessibility limitations, which SFPUC addresses by monitoring comments, using verified accounts, and distributing key updates across multiple, accessible channels.",2025/07/15,2025/07/18
SFPUC-Form Assembly,SFPUC,Form Assembly,Form Assembly is a web-based form platform that incorporates AI-powered features (such as AI Assist using ChatGPT) to enhance form creation and data collection.,"To automate the transformation of PDF forms into structured web forms for internal workflows and public data collection, reducing manual effort.","Used for digital service delivery of forms, constituent engagement, and internal operations.","Form Assembly does not train its own AI. It uses OpenAI's ChatGPT, trained on publicly available and licensed datasets.",Users upload a PDF; the integrated AI interprets form structure and content to generate a digital form. Human users retain editing control before publishing.,Structured response data from online forms.,Optimized for accurate field detection from PDFs. No quantitative performance metrics provided. Internal testing is recommended.,"Clean, well-structured PDF forms; standardized formatting.","Scanned images, poor formatting, handwritten text, or non-standard layouts.",No vendor-conducted bias testing documented.,Currently undocumented.,No formal tests described.,Not described.,High level of human-in-the-loop oversight.  AI output is reviewed and edited by humans before publication.,No. Form Assembly does not use user-submitted data for model training.,"City staff, residents, and external partners submitting or managing digital forms.",The City ensures accessibility and equity as per 22J.,Not addressed. Must ensure compatibility with assistive tech and conduct WCAG 2.1 compliance testing.,No jobs will be eliminated. Staff time may shift from manual form building to oversight and analysis.,"Improves efficiency in service delivery, accessibility, and reduces costs of manual processes.","Inaccurate form parsing, accessibility issues, or field bias. Mitigation: human review, internal testing, public feedback channels.",2025/07/15,2025/07/18
SFPUC-G Translate | Google Translate,SFPUC,G Translate | Google Translate,"G Translate is used to provide automated, real-time translation of website content into multiple languages, helping organizations like SFPUC improve accessibility and inclusivity for non-English-speaking users.",G Translate is a website add-in that leverages Google Translate functionality to provide automated translations.,"G Translate is intended to be used for digital communications. It provides language accessibility, inclusion and allow users to translate content into multiple languages for equitable communication across diverse populations.","G Translate |Google Translate AI is trained using large datasets of multilingual text, including publicly available translations, web content, professional translations, and user feedback. This data helps the system learn sentence structure, context, and meaning across languages using neural machine translation for more accurate and natural results.","G Translate, powered by Google Translate, uses neural machine translation (NMT) to automatically convert text from one language to another in real time. It is widely used to make websites and digital content accessible to users who speak different languages, including as a plugin on public websites like SFPUC.gov.","G Translate | Google Translate (also used in website integrations like G Translate) generates minimal user-facing data, but behind the scenes, it can produce both functional translation data and limited interaction metadata, depending on how it's implemented.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performanc+L10+[@[b8) Description of what the tech is optimizing for, it's accuracy, preferably w/ numerical performance metrics.]]",Transmission Range: Up to 15 km (9.3 miles) in open areas with minimal interference.,"Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",No formal user feedback loop on site; errors can be escalated to web team or Google Translate feedback.,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,G Translate powered by Google Translate does not have a built-in adverse incident monitoring system specific to translation accuracy,Low level of human-in-the-loop oversight. Automated translation engine with no manual review unless human correction is added on the site.,"No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",G Translate | Google Translate interacts with a diverse range of users and applications.,"G Translate | Google Translate, when used on SFPUC’s website via G Translate, helps expand access to essential public information for residents with limited English proficiency. This supports language equity and enables broader participation in City services, emergency communications, and community programs.","G Translate | Google Translate, including its use through G Translate on the SFPUC website, is generally compatible with assistive technologies such as screen readers, keyboard navigation, and browser-based accessibility tools. Users with diverse abilities can interact with the translation widget and translated content using tools.",No jobs will be eliminated.,Provides equitable communication to diverse populations through translation.,"G Translate | Google Translate  carries risks of inaccurate or misleading automated translations, which SFPUC mitigates by supplementing critical content with human-verified translations and offering information through multiple accessible formats.",2025/07/15,2025/07/18
SFPUC-Hootsuite,SFPUC,Hootsuite,"Hootsuite is a social media management platform, a social media listening tool designed to help organizations efficiently manage their presence across multiple social media networks from a single dashboard.","Hootsuite is a social media management platform designed to help organizations efficiently manage their presence across multiple social media networks from a single dashboard. Its core purpose is to optimize digital communications and engagement through a suite of tools for planning, publishing, monitoring, and analyzing content.",Hootsuite is used for social media management.,"Hootsuite's OwlyGPT, an AI co-pilot for marketers, is trained on real-time social media data. This approach allows the AI to understand current trends, brand tone, and sentiment, enabling it to provide timely and relevant insights based on ongoing social conversations.","Hootsuite is a social media management platform that allows users to manage multiple social accounts from one dashboard. It enables content creation and scheduling across platforms like Facebook, Instagram, LinkedIn, and X, with built-in tools such as Owl Writer AI and Canva integration. Users can monitor and respond to messages using the unified Inbox and Streams features, analyze social performance through Hootsuite Analytics, and collaborate as teams by assigning roles and permissions. It also supports managing paid social campaigns, allowing users to create and analyze both organic and sponsored content.","Hootsuite generates a range of data related to social media management, performance, and engagement","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Tools perform best with reliable data, network access, vendor configuration support, and operator training.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Vendors may conduct internal testing for bias. While Hootsuite leverages third-party AI models, such as those from OpenAI via Microsoft Azure, it is unclear whether these providers' bias testing protocols are integrated into Hootsuite's offerings.","Report through Hootsuite support portal or email (support@hootsuite.com). For immediate assistance,  contact Hootsuite on social media platforms like X (formerly Twitter) at @Hootsuite_Help.",Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"Hootsuite does support adverse incident monitoring and communication procedures, though it functions as an enabling tool rather than a dedicated incident response platform.","High level of human-in-the-loop oversight. Content is created, scheduled, monitored, and responded to manually by communications staff.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",Hootsuite is used internally by SFPUC for social media monitoring and response scheduling.,"Hootsuite may impact public rights if not managed for equity, accessibility, and transparency.","Hootsuite supports accessibility for people with diverse abilities through compatibility with assistive technologies such as screen readers, keyboard navigation, and alternative input devices. The platform follows WCAG 2.1 Level AA guidelines and offers keyboard shortcuts, clear visual hierarchy, and accessible navigation tools.",No jobs will be eliminated.,"Social media management is critical to support the general public, community in which services are provided to.","Hootsuite poses risks like account compromise, inaccessible messaging, and AI-generated errors, which SFPUC mitigates through secure access controls, content review, and use of official communication channels.",2025/07/15,2025/07/18
"SFPUC-Instagram 
(Meta)",SFPUC,"Instagram 
(Meta)","Instagram is a visual communication platform to share photos, videos, and stories that promote public awareness, community engagement, and transparency.",To share information and connect with the community.,"Instagram is used in the context of public communication, community engagement, and education. It serves as a visual storytelling platform.","Meta, the parent company of Instagram, utilizes publicly shared content from Instagram to train its artificial intelligence (AI) models. This includes public posts, photos, captions, comments, and interactions with AI features. Notably, content from private accounts, direct messages, and users under 18 is excluded from this data collection.","Instagram is a multimedia social networking platform designed for sharing photos, videos, and stories through mobile and web apps. It functions through a combination of cloud-based storage, AI-driven algorithms, and real-time content delivery systems","Instagram generates both user-created content and system-generated metadata, which are used for platform functionality, engagement tracking, and analytics.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Frequency Bands: Uses 2.4 GHz and 5.8 GHz, with automatic channel switching for optimal signal strength.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Go to https://help.instagram.com to  Report a Problem within the Application,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,Instagram uses a combination of automated detection systems and human moderation to monitor for adverse incidents.,"High level of human-in-the-loop oversight. Content is curated, posted, and managed by humans, with oversight on comments and interactions.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",People of all demographics use Instagram but use varies by age of the population.,"Information shared by SFPUC through Instagram may directly influence the public’s awareness of and access to critical resources such as emergency alerts, service disruptions, and community programs.","Instagram offers several built-in accessibility features and is compatible with commonly used assistive technologies such as screen readers, voice commands, and alternative input tools.",No jobs will be eliminated.,"Instagram is a vital communication tool for SFPUC because it enables the agency to reach a wide, diverse public audience with real-time updates about water, power, and sewer services, emergencies, and community programs.","Instagram risks include visual content inaccessibility, reliance on user-enabled alt text, and potential misinformation in comments, addressed by SFPUC through manual content reviews and use of additional platforms to ensure inclusive communication.",2025/07/15,2025/07/18
"SFPUC-LinkedIn 
(Microsoft)",SFPUC,"LinkedIn 
(Microsoft)",Social media platform for professional and career-oriented networking.,"Help individuals and organizations connect, share, and grow in their careers.","Workforce development, professional outreach, recruiting, and networking.","Profile information, activity logs, user interactions, and behavioral data.","AI/ML algorithms suggest connections, jobs, and content based on user data and network activity.","User engagement data, profile updates, connection activity, and job search metrics.","Connection relevance, job match rates, content relevance. Performance based on user engagement and feedback loops.","Updated user profiles, large and active professional networks.","Sparse or outdated user data, inactive users, or limited professional activity.","Microsoft/LinkedIn publishes transparency reports, but detailed bias audit disclosures are limited.","LinkedIn Help Center and feedback forms, or via privacy/reporting tools.","Tested with global professional user base, various industries, and use scenarios.","User reports, moderation teams, and AI-driven monitoring.",Mixed: AI-assisted recommendations with human moderation and review tools.,"No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.","Job seekers, recruiters, HR professionals, professionals in all sectors.","Can affect hiring opportunities, professional exposure, and career mobility.","Compatible with screen readers, keyboard navigation, and accessibility tools.",No. May automate aspects of recruiting and reduce some HR-related tasks.,"Useful tool for civic recruitment, workforce outreach, and public service engagement.","Bias in hiring, data misuse, platform manipulation. Mitigation includes transparency, audits, user education, and data policies.",2025/07/15,2025/07/18
SFPUC-Muck Rack,SFPUC,Muck Rack,"Muck Rack functions include monitoring news coverage, identifying and connecting with journalists, distributing press releases, and analyzing media impact.   Muck Rack support effective media relations and public communication.","Muck Rack is to enhance public outreach, respond to media narratives, and maintain transparency with the community.","Muck Rack is to enhance public outreach, respond to media narratives, and maintain transparency with the community.","Most tools are trained on public datasets, proprietary data, or user-generated content, depending on the development practices.","Muck Rack is to enhance public outreach, respond to media narratives, and maintain transparency with the community.","Muck Rack is a public relations (PR) and media monitoring platform that generates and collects data related to media coverage, journalist activity, and PR campaign performance.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Wind Resistance: Can handle winds up to 26 mph (12 m/s), but for precision tasks like mapping or inspections, calmer conditions are ideal",Ensure the gimbal and camera are properly secured and balanced to avoid drift or vibration,"Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Contact Muck Rack's Help Center here https://help.muckrack.com or use in-app chat support,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"Real-time alert features for monitoring, customizable tracking and communication procedures for adverse incidents.","Medium human-in-the-loop oversight. AI tools assist in journalist recommendations and PR impact scoring, but final outreach is human-directed.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",Internal media alerts system use for brand management.,"While Muck Rack aims to support journalists and PR professionals with valuable tools and data, the platform's role in curating information, utilizing algorithms, and facilitating communication by both private and public sector organizations means it has the potential to influence the information environment and therefore impact the public's rights, opportunities, and access to resources.","Muck Rack's user interface is primarily designed for communications professionals and is partially compatible with assistive technologies such as screen readers and keyboard navigation. While the platform offers basic accessibility features, it does not publicly document full compliance with WCAG 2.1 standards.",No jobs will be eliminated.,"Muck Rack is an essential media monitoring and communications tool for SFPUC because it enables real-time tracking of news coverage, public sentiment, and media narratives that can impact the agency’s operations, public image, and crisis response.","Muck Rack may pose risks related to inaccurate media tracking or unintentional bias in coverage analysis, which SFPUC mitigates by cross-verifying media insights and ensuring human review before public response or engagement.",2025/07/15,2025/07/18
SFPUC-Nextdoor,SFPUC,Nextdoor,"Nextdoor’s purpose is to foster community connection by providing a localized social networking platform where neighbors, public agencies, and local businesses can share information, resources, and services.","Nextdoor is a platform to communicate directly with residents about a variety of topics related to water, sewer, and power services.",Nextdoor is a platform to communicate directly with residents in the community about a variety of topics.,"Nextdoor trains its AI models using a combination of proprietary user-generated content and advanced language model techniques. The platform has developed a specialized model called LocalGPT, which is fine-tuned on OpenAI's GPT architecture to incorporate hyper-local data from specific neighborhoods and Designated Market Areas (DMAs). This training leverages organically tagged data from user interactions, such as posts about local events, items for sale, and content flagged for moderation, providing a rich dataset for developing localized AI capabilities.","The system uses algorithms sometimes AI-powered to interpret or act on data inputs, generate predictions, or automate tasks.","Nextdoor generates various types of data through its neighborhood-based platform, focusing on community engagement, public safety updates, and localized communication","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Tools perform best with reliable data, network access, vendor configuration support, and operator training.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",Use Nextdoor’s Help Center or flag content.,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"SFPUC monitors neighborhood conversations for reports of adverse incidents, such as water outages, flooding, or odor complaints and flags relevant posts for internal follow-up. SFPUC staff document incidents and responses for accountability and may coordinate with 311 or emergency services when broader intervention is required. This helps ensure accurate, localized communication and community trust during critical events.",High level of human-in-the-loop oversight. Posts and responses are written and monitored by agency personnel with verified accounts.,"No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.","Nextdoor is designed for use in the neighborhood and local community, where its primary goal is to foster real-world connections amongst neighbors, local businesses, public agencies, and organizations.","The San Francisco Public Utilities Commission  (SFPUC), recognizes that information disseminated through platforms such as Nextdoor can have a significant impact on the public’s ability to access timely updates, participate in civic activities, and connect with local resources.  The SFPUC remains committed to using such tools responsibly to ensure equitable access to information and engagement opportunities for all community members.","Nextdoor does not publicly claim full WCAG 2.1 compliance, and some users with visual or cognitive impairments may encounter barriers in navigation, content labeling, or dynamic updates. Accessibility may also vary between the mobile app and desktop version. Nextdoor is partially accessible to people with diverse abilities and provides basic support for assistive technologies such as screen readers and keyboard navigation. The platform’s web interface includes semantic HTML and labeling practices compatible with most modern accessibility tools.",No jobs will be eliminated.,To communicate directly with residents in the community about a variety of topics related to services.,"Nextdoor poses risks such as algorithmic bias, misinformation, and unequal access for non-users, which SFPUC mitigates by monitoring content, using verified agency accounts, and sharing critical information through multiple communication channels.",2025/07/15,2025/07/18
SFPUC-Skydio 10X Drone,SFPUC,Skydio 10X Drone,"Drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.","Drones are designed to provide aerial imaging, data collection, and autonomous flight capabilities for a wide range of uses, including photography, surveying, inspection, public safety, and environmental monitoring.",The Skydio 10X Drone is intended to be used for aerial photography and visual documentation.,The Skydio X10 drone's advanced autonomous capabilities are powered by AI models trained on a combination of real-world flight data and synthetic datasets.,"The Skydio X10 drone is a cutting-edge autonomous aircraft that blends advanced AI, powerful sensors, and rugged hardware to deliver high-performance aerial intelligence.","The Skydio X10 Drone is a high-performance, AI-powered drone built for autonomous operations, inspections, and tactical missions. It generates a robust set of visual, spatial, and system-level data to support detailed analysis and documentation.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Operating Temperature: Between -20°C to +45°C (-4°F to 113°F)
Wind Resistance: Handles gusts up to 28 mph (12.8 m/s), but calmer conditions are better for precision tasks
Weatherproofing: Rated IP55, meaning it’s protected against dust and low-pressure water jets suitable for light rain and dusty environments
Wireless Range:
Urban: 1–2 km
Suburban: 2–6 km
Rural: 6–12 km
5G Connectivity: Unlimited range where cellular coverage is available
GNSS Support: Compatible with GPS, Galileo, GLONASS, and BeiDou for robust satellite positioning
Startup Time: Under 40 seconds, ideal for rapid deployment
Obstacle Avoidance: True 360° coverage using six 32MP navigation cameras ensure sensors are clean and unobstructed
Flight Time: Up to 40 minutes under ideal conditions; hover time is around 35 minutes","Adverse Weather Conditions, Signal Interference & Connectivity Issues, GPS-Denied Environments, Terrain Following Disabled, Environmental Extremes","As of now, there is no publicly available information indicating that Skydio has conducted or published testing to assess potential biases—such as those based on race, gender, or other demographic factors—in the AI systems of its X10 drone. The available documentation and resources focus primarily on the drone's technical specifications, imaging capabilities, and operational performance in various environmental conditions .","Report bias to: https://www.skydio.com/contact. Use this form to raise technology ethics, performance bias, or civil rights issues in Skydio deployments.","Environmental Stress Testing (tested in light rain, dust, and wind gusts up to 28 mph,  validated for performance between -20°C to +45°C (-4°F to 113°F), including cold-weather missions using self-warming batteries to prevent shutdowns in sub-zero environments)
Low-Light & Night Operations (equipped with a FLIR Boson+ sensor, it has been field-tested for search and rescue, firefighting, and tactical surveillance, detecting heat signatures with <30mK sensitivity)
Industrial & Infrastructure Inspections (The drone has been deployed to inspect cracks as small as 0.1mm, using its 64MP narrow camera and AI-assisted flight paths to autonomously scan complex structures, In one field report, the X10 mapped a 12-acre wildfire perimeter in a single battery cycle, navigating through smoke and shifting wind using its obstacle avoidance system)
Tested for onboard 3D scanning and mapping, the X10 autonomously captures and processes data without external software, even in GPS-denied environments.","It issues escalating alerts such as “Return Battery Capacity Reached,” “Land Soon,” “Drone Battery Low,” and “Land Immediately”, each with visual and audible warnings on the controller
Operators can configure the drone to either Return to Home or Hover if the connection is lost.
If no action is taken within a set time, the drone will autonomously return or land, depending on the settings
If GPS is lost, the X10 switches to vision-based navigation.
In extreme cases (e.g., high elevation with no visual cues), it enters a barometer-based altitude hold mode and may initiate an emergency landing if no pilot input is detected
Flight Log Archiving:
All telemetry, video, and incident data are securely stored and can be reviewed for compliance, training, or investigation.
Autonomous Landing Adjustments:
In low battery or emergency scenarios, the drone seeks a flat, safe landing zone, making minor adjustments to avoid hazards. Automation has ability to terminate flight.","Medium to High level of human-in the loop. Autonomous navigation with obstacle avoidance, but missions are planned, monitored, and reviewed by operators.","Skydio provides open APIs and developer tools that allow users to integrate with third-party systems (e.g., Drone Deploy, Pix4D, Trimble).
If users upload data to these platforms, those services’ data policies apply—some may use anonymized data to improve their own tools, but this is governed by their terms of service
Operators retain full ownership of the data captured by the Skydio X10.
Data is stored locally on encrypted media and can be uploaded to Skydio Cloud or third-party platforms at the user's discretion.
Skydio emphasizes compliance with NDAA and cybersecurity standards, especially for defense and government clients
Skydio has not publicly stated that it uses customer-collected data to train its own AI models.
The X10’s autonomy is powered by onboard AI (e.g., NVIDIA Jetson Orin GPU), which processes data in real time without needing to upload it for cloud-based learning. No automatic opt-in exists for data sharing with Skydio or third parties for model training.","Drones are internally managed and operated by trained staff and contractors for purposes such as inspections, monitoring, and project documentation. Individuals who interact with this technology include agency personnel, nearby residents, and community members who may view drone imagery through public updates or reports.",SFPUC drone data can improve public rights by enhancing how infrastructure services are monitored and delivered.,Drones used by SFPUC do not have direct user interfaces designed for public interaction.,No jobs will be eliminated.,"Drones are a critical tool for SFPUC because they enable safe, efficient, and cost-effective inspection, monitoring, and visualization of infrastructure and environmental conditions, especially in areas that are difficult, hazardous, or expensive to access by ground.","The Skydio X10 drone presents several risks, including battery-related failures, environmental hazards, impaired obstacle avoidance, operator error, and supply chain disruptions. To mitigate these, human-in-the-loop approach is necessary.   Additional safeguards include autonomous failsafe behaviors and contingency planning for hardware supply limitations.",2025/07/15,2025/07/18
SFPUC-X (Formerly Twitter),SFPUC,X (Formerly Twitter),"A social media platform that is known as a 'microblogging' system. The purpose of X is to serve as a real-time public platform for sharing short-form content, updates, and discussions. It emphasizes news, trends, opinions, and rapid communication between individuals, organizations, and the public.",X (formerly Twitter) as a platform for communication and public engagement.,Deployed for communication and public engagement.,"X uses AI through its integration with X AI's Grok chatbot, which is powered by X AI's state-of-the-art large language model (LLM).","X is a real-time, microblogging and social networking platform designed to share short messages (""posts"" or formerly ""tweets"") and multimedia content. It operates through a combination of cloud infrastructure, content delivery systems, and machine learning algorithms to deliver fast, relevant, and personalized experiences to users.","X generates real-time data based on user activity, public engagement, and platform interactions.","Optimized for automation speed, pattern recognition, communication clarity, or visual accuracy; performance varies by use case and vendor metrics.","Lighting: Performs well in low-light conditions thanks to its Smart Low-Light Photo mode, but direct sunlight or glare can affect image quality.","Performance may degrade due to data quality issues, system outages, integration failure, or environmental conditions.","Where applicable, vendors may conduct internal testing for bias. The City reviews systems that affect the public or automated decisions.",https://help.twitter.com,Tools are piloted or tested in internal use cases or designated programs before broader implementation.,"Internal detection and monitoring tools: X uses internal tools to detect and alert them of unusual behavior or unauthorized access attempts to their internal systems, including critical resources.","High level of human-in-the-loop oversight. Requires manual drafting, monitoring, and public interaction by agency communicators.","No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.",People of all demographics use X but use varies by age of the population.,"Information shared by SFPUC through X may directly influence the public’s awareness of and access to critical resources such as emergency alerts, service disruptions, and community programs.","X (formerly Twitter) offers several accessibility features and integrates with commonly used assistive technologies such as screen readers, keyboard navigation, and voice input tools.",No jobs will be eliminated.,"X (formerly Twitter) is a vital communication tool for SFPUC because it enables the agency to reach a wide, diverse public audience with real-time updates about water, power, and sewer services, emergencies, and community programs.","X presents risks such as reduced content reach due to algorithmic feeds, limited accessibility, and potential exposure to online harassment, mitigated by SFPUC through active moderation, content redundancy, and alternative communication tools.",2025/07/15,2025/07/18
"SFPUC-YouTube
(Google/Alphabet Inc.)",SFPUC,"YouTube
(Google/Alphabet Inc.)","Video-sharing platform for uploading, viewing, sharing, and commenting on videos.","Public video communication, education, outreach, and engagement.","Public communications, education, city announcements, and civic engagement.","Public user behavior data, video metadata, user feedback (e.g., likes/comments), automated content analysis.","Uses AI to recommend videos based on engagement, watch history, and trends; allows video uploads and comments.","Engagement metrics (views, likes), user comments, recommendation trends, watch history.","Engagement, watch time, ad revenue. Accuracy is difficult to measure but is driven by click-through rate (CTR) and viewer retention.","Active user base, rich metadata, timely and relevant content.","Poor metadata, outdated content, algorithmic bias or manipulation.",Google has published research on algorithmic fairness but detailed bias testing results are not fully public.,"YouTube Help Center, user feedback options, and abuse report forms.","Tested across global populations, device types, and network conditions.","Community guidelines enforcement, content reporting, and automated flagging.",Mixed: automated moderation plus human review for flagged content.,"No. Unauthorized use of City Data by Contractor, subcontractors, or other third-parties is prohibited.","General public, content creators, educators, city departments, youth.","Can shape public perception, access to information, and community engagement.","Supports captions, screen readers, and keyboard navigation.",No. Technology reduces the need for traditional outreach staff in-person and creates new learning opportunities.,"Useful tool for mass communication, education campaigns, emergency alerts.","Misinformation, privacy breaches, algorithmic bias. Mitigation via content policies, moderation, transparency reports.",2025/07/15,2025/07/18
POL-PenLink,POL,PenLink,"ï PenLink, Ltd provides state-of-the-art software and systems for the collection, storage, and analysis of telephonic and internet-based communications. PenLinkís software and systems are widely recognized as industry standards, with thousands of users across hundreds of federal, state, and local law enforcement agencies throughout the United States and abroad. PenLink PLX is the latest in a long line of PenLink communications collection and analysis products, spanning over 30 years of excellence and innovation in serving the needs of law enforcement. ï PenLink PLX is a comprehensive platform capable of collecting historical communication records through subpoenas or search warrants or conducting live interception of communications. It can collect transactional data only, like CDRs or pen register data, or full content such as social media search warrants or live wiretaps. PLX can collect phone calls, text messages, MMS, app-based communications, emails, social media activities, and other internet-based communications. ï PenLink leverages Microsoft Azure AI Services for machine-based transcription and translation of collected audio and text communications, as well as machine-based image tagging to organize images into categories that help analysts quickly locate and examine relevant images.","ï Rapidly convert lawfully authorized collected communications into accurate and searchable text. Save time in data analysis, uncover new leads, and expedite investigations. Image tags help prioritize the most critical images for review. This is not generative AI.",ï Used exclusively within the PLX product for machine-based translation/transcription and image tagging; does not contain generative AI.,"ï Utilizes Microsoft Azure AI transcription, computer vision, and translation services.","ï PLX users choose to transcribe audio or translate text stored within PLX. The audio is sent to a PenLink API deployed in the Azure Government cloud region, which interfaces with Azure transcription services. Once processing is complete, text is stored in the PLX database and accessible in the Language Assistant tab. Audio is not stored in the cloud after processing. ï When images are tagged, they are sent to a PenLink API in the Azure Government Cloud, which interfaces with Azure Computer Vision services. Tags categorize images for efficient review. Images are only stored in the PLX database, not in the cloud.",ï The technology returns machine-based translations and transcriptions for user review; it does not generate new data.,ï PLX uses Microsoft Azure AI speech-to-text. Microsoft provides details on optimization and accuracy.,ï Higher quality audio and images improve results from Azure AI.,ï Lower quality content negatively impacts Azure AI results.,ï PenLink defers to Microsoft regarding bias identification and testing.,ï Any inaccuracies from Microsoftís responses can be reported to PenLink support.,"ï PenLinkís development and QA teams have tested a variety of file types, languages, and image types.",ï The San Francisco PD PLX deployment is hosted on-premises; PenLink does not monitor the system.,ï The SFPD system is hosted on-premises; PenLink does not monitor it.,ï No data is stored on external servers for training purposes.,"ï Access to translations, transcriptions, and image tags is limited to the PLX application.",ï The technology enhances existing collected communications; it does not generate new information.,ï PLX is a visual analytical tool with user interface consistent across the application.,ï The technology does not replace jobs but improves efficiency in analysis.,"ï Enhances investigative efficiency, breaks language barriers, increases productivity, reduces costs, and accelerates communication review.","ï As an on-premises solution, San Francisco PD personnel should review results for inaccuracies or issues.",2025/07/17,2025/08/18
POL-VIQ Solutions,POL,VIQ Solutions,aiAssist generates speech recognition drafts and identifies speaker transitions.,"To make transcription more efficient by providing drafts to the transcriptionists to edit, rather than having them type everything from scratch.",Transcription services.,"We are using pre-trained models. We have not selected the data that gets into these models, but our understanding is that the training data contains a very large amount of textual and audio data from a number of domains.","We send audio files into aiAssist, which generates a speech recognition drafts with speaker transitions. The draft contains words with audio timing information to allow the NetScribe editor to play the audio while highlighting the current word.","Speech recognized words, timings, and speaker labels, in JSON format, which then gets converted to HTML for editing.","Itís optimized to reduce the word error rate (WER) and diarization error rates (speaker transitions), quickly.","Having good audio quality is the single most important factor in producing high-quality speech recognition drafts. After that, good dictation habits, clear pronunciation, not having many speakers all talking at the same time, etc.","Bad audio quality, bad dictation habits, background noise, multiple speakers talking simultaneously.",We have done no specific tests for these factors.,"To our knowledge, no one has reported biases. Inaccuracies stem from the factors noted above and also from the inherent limitations of the technology.","Predominantly, court work, law enforcement work, insurance work, finance work, and general dictation.","We provide two services: 1) send the speech recognition drafts directly to the customer as is (aka FirstDraft), and 2) send professionally edited documents. In the former case, the customer is responsible for correct utilization of data that may contain errors. In the latter case, VIQ Solutions is responsible for delivering a professionally edited document utilizing a multi-layer editing and QA process.","For FirstDraft jobs, there is no human oversight of the process before delivering the job to a customer. For professionally edited jobs, we have humans review and correct deficiencies in the documents.","VIQ does not use customer data to train any third-party systems. VIQís patent-pending Domain Specific Language Model (DSLM) does leverage actual audio and the resulting, anonymized verbatim transcription corrections to improve the quality of the speech recognition. DSLMís are privately hosted within VIQís cloud infrastructure and can be fully gated at the client level, i.e., if preferred, we can restrict your data from our DSLM.","Entities where audio and video data are captured and must be transformed into a document. We especially focus on court work, law enforcement, insurance, finance, and then general dictation.","The speech recognition and editing processes arenít really creating information. They are transforming audio information to another format, i.e., a document. The system is not making any decisions outside of how to create an accurate document.","We typically deliver documents back to customers who are then responsible for disseminating those documents to their user population. Users can also interact with VIQís NetScribe Connect portal to view documents online. We donít specifically integrate with any assistive technologies, though users may install applications on their computers that could potentially assist users.",The technology is used to make the transcription process more efficient and to provide a faster turnaround time in transforming audio to text. It is not being used to impact employment or working conditions of City workers.,This decision should be at the countyís discretion after considering the information provided.,"Speech recognition is a process with an inherent risk is accuracy. Thus, we use it as a tool for efficiency but then edit the text as needed to produce a high-quality document. In some cases, however, fast turnaround time of the document is very important, so we offer FirstDraft for these use cases, and leave the responsibility of how best to use the draft documents to each customer.",2025/07/21,2025/08/18
POL-Axon,POL,Axon,"Redaction Assistant - A tool integrated into Axonís Redaction Studio, designed to assist law enforcement in automating the process of video evidence redaction. This tool leverages advanced artificial intelligence specifically tailored for law enforcement applications to streamline and expedite the redaction of sensitive information. Auto-Transcribe - Axon Auto-Transcribe optimizes the evidence processing workflow by utilizing next-generation technology to create fast, accurate transcripts. This not only aids in saving time and resources but also enhances the capabilities of law enforcement professionals in their investigative tasks. All transcripts are completed within 5 minutes regardless of length.  Automated People Detection (APD) - now called ""Smart Detection,"" is available in Axon Evidence to enhance video analysis by identifying individuals within footage captured from Axon Body 3 and Axon Body 4 cameras. This tool aims to simplify and accelerate the video review process. Draft One - Draft One is a narrative generation tool integrated within Axon Evidence, designed to assist law enforcement officers in creating draft narratives for incident reports quickly and efficiently.","Axonís suite of AI-powered toolsóRedaction Assistant, Auto-Transcribe, Smart Detection, and Draft Oneósignificantly enhances San Francisco PD's efficiency by automating time-consuming tasks and reducing human error. Redaction Assistant streamlines the video redaction process by automatically identifying and masking sensitive information, saving hours of manual effort while minimizing the risk of overlooking critical elements. Auto-Transcribe delivers fast, accurate transcripts within five minutes regardless of video length, drastically cutting down on administrative workload and enabling quick, searchable access to spoken content. Smart Detection (formerly Automated People Detection) enhances video review by automatically tagging individuals in footage from Axon Body cameras, allowing users to skip directly to  relevant scenes and reducing the chance of missing key subjects. Draft One accelerates incident report writing by generating narrative drafts based on evidence, helping officers produce structured, complete reports more quickly and consistently. Together, these tools save substantial time, reduce administrative burdens, and increase accuracy across critical areas of evidence processing and documentation.","The technologiesóRedaction Assistant, Auto-Transcribe, Smart Detection, and Draft Oneóare intended to be used within the law enforcement context, specifically to support the operational, evidentiary, and administrative functions of the San Francisco Police Department (SFPD). These tools are designed to enhance the handling of digital evidence collected through body-worn cameras, interviews, and incident reports. Within this domain, their application supports transparency, accountability, and investigative efficiency by streamlining workflows associated with video redaction, transcription, suspect identification in footage, and report writing. This is especially relevant in a high-volume, urban policing environment like San Francisco, where officers frequently manage large quantities of digital evidence under tight deadlines, public records requests, and court preparation requirements. These technologies help ensure compliance with legal standards while reducing administrative strain on officers and staff.","By default, Axon mainly uses data that's self-collected or synthetically generated to train AI models. We prioritize ongoing development of our products without the use of customer data wherever possible. For example, when testing its own ALPR tooling, Axon self-collected plate data in certain U.S. States by leveraging vehicles equipped with cameras to capture and record plate information. Axon confirmed such collection was and remains in compliance with applicable U.S. State Laws. This provided Axon with set of test data that was legally and ethically collected. Training data is defined and refined to ensure only relevant data is included. At each stage, the data is assessed to confirm it meets needs and remains accurate. We leverage feedback loops to identify and manage any data drift and address them. Any issues are identified, documented and resolved through the AI team with inputs from our legal team and senior leadership. For instances where customer data is truly necessary for improvements, we leverage the Axonís Customer Experience Improvement Program (ACEIP). This program is a voluntary ethical and privacy-centric program that allows customers to share data with Axon to help develop new products and improve our customersí product experience. When customers choose to participate in ACEIP, agencies continue to remain in control of their data and can decide to leave the program at any time and also request that we delete their data if our relatively short  retention periods haven't done so already. ACEIP data is stored in our highly secure environment. The ACEIP program is only available for customers within the United States. As appropriate to the use case and data set, Axon leverages Privacy-Preserving Techniques to extract aggregated, transformed, or de-identified elements or segments of data, so that the extracted data is no longer reasonably capable of being associated with or could reasonably be linked directly or indirectly to a particular individual. In the case where Axon may need to use identifiable and unaggregated data, customers must explicitly opt-in as part of the ACEIP Tier 2 program via a specific contractual agreements with Axon. Training data is defined and refined to ensure only relevant data is included. At each stage, the data is assessed to confirm it meets needs and remains accurate. We leverage feedback loops to identify and manage any data drift and address them. Any issues are identified, documented and resolved through the AI team with inputs from our legal team and senior leadership","Redaction: AI for redaction in Axon products is utilized to automatically identify and obscure sensitive information within video and audio recordings. By leveraging advanced machine learning algorithms, Axon's redaction tools can analyze footage to detect attributes or items that need to be concealed. This process not only streamlines the redaction workflow for law enforcement agencies, but also preserves the privacy of individuals, allowing law enforcement to share necessary information without compromising sensitive data. Axon Auto Transcribe (Transcription): Axonís use of LLM to automatically transcribe footage captured from Axon camera devices. This reduces transcription time for video or audio files to just minutes, then effortlessly find key moments by scanning the transcript or using keyword searches to jump to significant moments. Automated People Detection (ADP): Automated People Detection is a tool within Axon Evidence that provides a thumbnail view of distinct people found within a video file. This helps investigators quickly find key moments in digital evidence, for example jumping to the 30-minute mark of the video when a person first appears, rather than watching 30 minutes of uneventful footage first. Importantly, people detection does not detect any facial features, nor does it assign individual identities to human forms detected. To put it simply, Automated People Detection can tell investigators that based on the shape of an object in digital evidence, it believes that object to be a person generally. But it is not actually identifying that individual, it is merely pointing out that a human is visible in the evidence, and where relevant, that there are multiple distinct individuals.  Draft One: Draft One leverages LLM to automate the initial and first drafting of documents, such as reports and citations based off of BWC recordings. The AI system streamlines information input and promotes accuracy by utilizing templates and pre-filled data from previous incidents. This service reduces the time officers spend on administrative tasks, however, officers are always required to review and correct initial drafts created by Draft One to promote accountability.","Redaction: AI for redaction in Axon products is utilized to automatically identify and obscure sensitive information within video and audio recordings. Axon Auto Transcribe (Transcription): Axonís use of LLM to automatically transcribe footage captured from Axon camera devices. Automated People Detection (ADP): Automated People Detection is a tool within Axon Evidence that provides a thumbnail view of distinct people found within a video file. Draft One: Draft One leverages LLM to automate the initial and first drafting of documents, such as reports and citations based off of BWC recordings.","Redaction: streamlines the ability to detect and then blur objects that would warrant privacy protection technologies and controls within police evidence. Accuracy varies by object: Screens 88%, Head Detection 81%, License Plate 87%. Axon Auto Transcribe (Transcription): Streamlines ability to review footage by enabling user to serach transcription. Word Error Rate (WER) in English: Indoor Diaglog (5.51%) Outdoor Dialog (9.41%) ADP Smart Detection: Enables users to review footage faster by flagging unique indivduals within footage. People Capture Rate (PCR) 86.87% Draft One: Streamlines generation of report based on camera footage. Consistency Errors per draft (4.33 mean, 8.0 P95; above 5.0 P95 target)","Redaction: Sufficient video quality (e.g., lighting, pixelation) Axon Auto Transcribe (Transcription): Sufficient audio quality  Automated People Detection (ADP): Sufficient video quality Draft One: Sufficient audio quality",Redaction: Poor video quality that would prevent the ML algorithm from identifying objects Axon Auto Transcribe (Transcription): Poor audio quality preventing accurate transcription. Automated People Detection (ADP): Poor video quality that would prevent the ML algorithm from identifying objects Draft One: Poor audio quality preventing accurate transcription.,See the Draft One study here https://a.storyblok.com/f/198504/x/7a83779017/axon_marketing_draft-one_double-blind-study_fnl.pdf,"Report bias, inaccuracies, or poor performance of the technology can be sent to support@axon.com.",See study details above.,"Axon continuously monitors and improves AI security by leveraging advanced security analytics tools such as anomaly detection systems, SIEM platforms, and structured security assessments focused on AI vulnerabilities. External audits with leading cybersecurity organizations and rigorous AI model testing help proactively identify and mitigate risks before they impact real-world applications. Our Legal team, Government Affairs, and AI leadership closely monitor AI legal and regulatory changes to align our security approach with the future direction of AI as it evolves.  By embedding security, privacy, and ethical considerations at every stage of AI development, Axon not only upholds the highest standards of trust and reliability but also ensures our AI-powered solutions empower law enforcement and public safety professionals with confidence and accountability.","Axon prioritizes responsible AI deployment by maintaining human oversight through structured review processes and operation safeguards, such as mandatory human approvals and real-time monitoring. Key commitments include: Human-in-the-Loop Oversight: AI-powered tools are designed to assist, not replace, human decision-making. Officers and investigators retain full control over AI-generated outputs by reviewing, modifying, and approving AI-generated content before any operational use. Axon also employs robust logging, monitoring, and event response mechanisms to track AI-related activities, detect anomalies, and respond to potential risks in real time, ensuring transparency and accountability. Preventing Model Overreach: Our AI systems operate within strict permissions by enforcing role-based access controls and explicit approval processes, ensuring they do not undertake actions beyond their intended scope. Mitigating Bias and Fairness Risks: AI models undergo comprehensive fairness testing through statistical bias analysis, adversarial testing, and iterative improvements. Bias metrics and performance evaluations are documented and reviewed before release to maintain fairness and equity. Transparency and Explainability: Axon's AI development methodologies and security controls are created in explainable formats for customers, ensuring clarity and accessibility.","Police data is sensitive in nature, so it is essential that the SFPD protects their data, and that it is not used for training vendor or third-party systems. With Axon AI, agency data is securely housed within Axon Evidence. If Axon needs to test with real customer data, they request permission to enroll customers in our voluntary, privacy-centric program ó all while working within the confines of their data sharing agreement.  Axon maintains an Information Security and Privacy Program to ensure the protection of customersí data and operations when using Axon products and services, while meeting the necessary regulatory, compliance, and contractual requirements. These include internationally recognized certifications such as ISO/IEC 27001 for information security management, ISO/IEC 27018 for cloud privacy, SOC 2 Type 2 for service organization controls, and CSA STAR Level 2 for cloud security assurance. For a full overview of information security certifications, visit the Axon Trust Center.",Persons or objects recorded in video/audio. Personnel interacting with recorded video/audio within SFPDís Evidence.com,"Based on Axonís Responsible Innovation Framework, the potential impact of its technologies on the publicís rights, opportunities, and access to critical resources or services, as well as on the employment and working conditions of City workers, is expected to be low due to the companyís ethical, human-centered approach. Axon designs its technologies to support and enhance public safety and implements privacy and transparency controls. Importantly, Axon does not develop or deploy technologies that make automated decisions about humans; instead, human judgment is always required in decision-making processes. This ensures that technology serves as a tool for public safety professionals, not a substitute for their discretion or accountability. Axon AI is intended to increase efficiency and transparency without replacing human oversight. Additionally, Axonís ongoing collaboration with its Ethics and Equity Advisory Council (EEAC) further helps ensure that its technologies minimize risks and do not negatively affect individual rights.","At Axon, we are committed to delivering accessible and inclusive products that meet the needs of all our clients. To ensure compliance with the Web Content Accessibility Guidelines (WCAG) 2.2 Level AA, we regularly test our products using a variety of assistive technologies and partner  with leading experts in accessibility. As part of our transparency and dedication to accessibility, we provide Voluntary Product Accessibility Templates (VPATs) upon request. These documents outline our efforts to align with accessibility standards and detail the steps we have taken to identify, address, and resolve accessibility issues. Download the latest VPAT at https://trust.axon.com/?itemUid=d419832d-aad8-4b0f-a269-22ba6751e4cc&source=title","The goal of this technology is not to replace any jobs currently being performed by humans, but rather to improve their working conditions by making them more efficient and effective at serving the city of San Francisco. Axon builds AI-enabled technology with controls so that the solutions never remove human decision-making in critical moments. The average American officer spends up to 40% of their time in paperwork. These AI tools will reduce the amount of time our officers spend on administrative tasks, thereby improving the amount of time they can spend in the community and accelerating the justice process. For officers, this means fewer overtime hours, less burnout, and more time to focus on the part of the job they love. For the community, it means safer streets, faster response times, and a quicker resolution to any incidents they encounter.","There are several key reasons it is important for the city to use Axon AI Technology. First, the city's police force is more than 500 officers short of the minimum staffing level (source). These AI tools can help reduce the administrative workload of SFPD officers, giving them more time to respond to calls for service and be present in our community, despite the challenges of being understaffed. This technology can also help the SFPD with recruiting, as new officers are looking for agencies who use new technology to reduce administrative workloads. Second, Axon AI technology can support our community by reducing response wait times and improving the speed at which cases are investigated and moved through the system. Less time for paperwork mean officers will have more time to respond to 911 calls. Tools like Smart Detection and Redaction Assistant mean officers can build cases and redact them more efficiently, thereby increasing the speed cases can move to the justice system or evidence is shared with the appropriate channels. Third, Axon AI technology is built and designed for the needs of public safety. The technology is integrated into SFPD's existing workflows, which will improve the speed and quality of adoption. It is built with strong data security, rigorously tested for accuracy and bias, and requires humans to review and approve the work. As more and more people  adopt AI into their workflows, it is essential that we give our officers toolss that have been designed specifically for public safety.","The primary risks associated with the use of this technology stem from the possibility that human officers may choose not to thoroughly review the outputs generated by AI assistance. To mitigate these risks, several proactive measures can be implemented.  First, Axon AI tools are intentionally designed to reinforce human oversight. For example, Draft One includes multiple safeguards that require officers to review and approve draft reports before they can proceed, thereby ensuring that final decisions remain in human hands.  Second, we will update our internal policies to reflect industry best practices for AI usage. These updates will clearly outline the expectations and responsibilities of officers when working with AI tools.  Third, we are committed to providing comprehensive training to our officers. As AI continues to evolve, the demand for guidance and education is high. Our training program will not only teach officers how to effectively use these new tools but will also emphasize the critical importance of responsible and ethical AI use.",2025/07/21,2025/08/18
POL-Motorola Solutions Inc.,POL,Motorola Solutions Inc.,Motorola Solutions VM Assist technology is a Large Language Model technology to help streamline searching and other workflows in the VehicleManager product. The intent is to make the human-machine interactions more simple and more direct while leveraging AIís power to summarize complex data sets.,The main use of the technology is to streamline VehicleManager workflows while improving accuracy of locating vehicles of interest.,The technology is intended to reduce investigation times by improving the ability to identify vehicles of interest.,VehicleManager AI is from Motorola Solutions. We use our own data and do not use public safety data to train our AI models.,"When a vehicle is detected, AI will analyze the image to derive important data such as the vehicleís color. This data is indexed and made available for future searching.","The VehicleManager AI will generate a number of facets for each detection including the vehicleís make, model, color, and other attributes.","We are optimizing both accuracy and speed for Core AI models. This includes object detection on vehicle model, vehicle class, license plates (including registration state), vehicle colors, and vehicle types. We analyze unique vehicle characteristics like damage, stickers, logs, signage.",We suggest following our LPR camera installation recommendations and our recommendations for using prompts with VM Assist. These guides provide optimal image conditions for capturing vehicle detections.,"Essentially, not following the recommendations mentioned in item (9).","The technology itself focuses on vehicles and not people, thereby avoiding bias. VM Assist does not in any way associate vehicles with people. Motorola Solutions has also implemented ìguardrailsî for natural language queries in the system. We thoroughly test our guardrails.",VM Assist is covered by the standard VehicleManager support process.,"Motorola Solutions uses multiple layers of testing with our Assist application: direct queries, AI-assisted red teaming, and OWASP LLM Security Verification Framework.","Motorola Solutions uses the latest Application Performance Monitoring (APM) and Observability techniques to monitor system performance, including monitoring our LLM system. We maintain detailed audit logs for customer use as well. Should an event occur, we engage our storm plans","Users determine when to perform searches, what criteria to search, confirm matches, and undertake further action. All actions are audited and ultimately are human verified before outputting results. Motorola Solutions conducts regular reviews of the system to ensure regulatory compliance and ìintended useî.",Motorola Solutions does not use public safety data to train VehicleManager AI models,The technology is for use by public safety agencies to support lawful investigative processes.,"The technology is used to identify vehicles-of-interest including their location and travel times and as such must be used for lawful investigative processes. Users take the meaningful action of providing an audit purpose, and based on their LPR Policy, confirm proposed matches. Motorola provides clear tools and user interfaces to verify the proposed matches.",Speech-to-text accessibility solutions can be used with the VM Assist application.,The technology speeds up the process of identifying vehicles of interest.,VM Assist provides a force multiplier which can reduce investigation times and increase positive outcomes. The technology often finds video evidence that may have been overlooked. VM Assist can also suggest next steps that may yield a more favorable outcome.,"The biggest risk with any LLM technology is detecting and mitigating a malicious prompt attack. Motorola Solutions designs and tests to prevent these scenarios, including the prevention of divulging data. Furthermore, the tooling does not interact with the public nor public data via any sort of UI. It is a closed solution that interacts only with the data on our system",2025/07/22,2025/08/18
POL-Motorola Solutions Inc.,POL,Motorola Solutions Inc.,"It is designed for law enforcement to track vehicles for the purpose of generating investigative leads and issuing real-time alerts. The system uses in-house developed Machine Learning (ML) models for tasks such as License Plate Recognition, vehicle detection and classification, vehicle attribute recognition (make, model, color, body markings, damage), and speed estimation. It seamlessly integrates with CommandCentral Aware and supports both mobile and fixed License Plate Recognition (LPR) cameras through a user-friendly interface, all while adhering to CJIS-compliant security standards. Mitigation Strategies. The Vehicle Manager system is specifically trained to identify license plates and associated vehicle attributes. All collected data is secured and private, utilizing end-to-end encryption and adhering to CJIS-compliant standards. Customers receive comprehensive training to ensure proper use and reduce the risk of incorrect identification. Importantly, the system itself cannot and does not identify individuals using its License Plate Recognition (LPR) capabilities. It focuses solely on vehicle identification.","Its primary purpose is to streamline vehicle tracking and identification through real-time analytics, predictive insights, and integration with systems like CommandCentral Aware, PremierOne, and Spillman Flex. Applied in patrol vehicles, mobile command centers, and fixed surveillance setups, VehicleManager helps law enforcement agencies improve situational awareness, accelerate response times, and enhance operational effectiveness in missions such as crime prevention, suspect tracking, and public safety management.","The technology is specifically designed for domains characterized by high volumes of visual data (images, videos) from vehicle activity and a critical need for rapid, intelligent information retrieval and event analysis: ? Public Safety: Analyzing incident footage, identifying suspects, tracking movements, and gathering evidence for investigations. ? Physical Security: Monitoring vehicle access, ensuring compliance, and detecting anomalies for enhanced site security. ? Smart City Management: Analyzing traffic patterns, responding to incidents, and enforcing parking in city surveillance.","Our technology is trained on a proprietary dataset, self-collected, processed, and meticulously labeled to power custom AI models for vehicle detection, license plate recognition, make/model, color, state, vehicle type classification, anomaly feature detection, vehicle part detection.","Data Ingestion Process: We turn raw vehicle images into intelligent, searchable information. Our advanced AI models automatically analyze every frame to extract key details like vehicle type, make, model, color, license plates, and even anomaly features like damage, stickers. This rich, structured data is then instantly indexed, making it ready for powerful, precise searches.","The data generated by the offline process: ? Vehicle facet: license plate number, vehicle make, model, color, general type (e.g. sedan, suv) ? Vehicle attributes: detection of damage, sticker, tool equipment, text, and identification of vehicle parts (e.g. windshield, rear window) ? Embedding vector",We are optimizing both accuracy and speed for Core AI models: ? Vehicle detection: ? Accuracy: ? Latency: ? License plate recognition ? Vehicle Make/Model recognition ? Vehicle attribute analysis,"? High quality visual data input: ? Resolution & Clarity: Images should be of sufficient resolution and free from excessive blur, noise, or compression artifacts. ? Lighting: Well-lit conditions are best, without too much or too little light, and without strong backlighting that hides car details. ? Angle & Visibility: Vehicles should be clearly visible with minimal occlusion (e.g. not blocked by other vehicles, trees, or structures). Angles that clearly show license plates, vehicle sides, and major components are preferred.","? Poor Visual Data Quality ? Low resolution & blurriness ? Suboptimal lighting ? Heavy occlusion: when vehicles are largely blocked by other objects (other vehicles, trees, buildings, heavy fog, rain, snow) ? Cameras positioned too far, too high, or unusual camera angles","Yes. Our models are tested for bias against our specific analysis features. This includes ensuring uniform accuracy across all US state license plate designs, various vehicle colors, and types.","Use the ""Feedback"" session on our service or email our support team to report any errors. You can report a misidentified make/model, an incorrect color, a wrong state of origin, or if a sticker is misinterpreted. This user feedback is crucial for our continuous improvement.","We test our technology using a massive dataset featuring all US state license plates, a vast spectrum of vehicle colors, and countless models. Our system is validated in varied lighting, weather, and angles, and specifically tested on its ability to detect and differentiate various features on vehicle bodies.",We also have a dedicated team that reviews all user-reported inaccuracies to rapidly correct any systemic issues.,"Our human oversight is a continuous improvement loop. A dedicated team actively reviews the analysis results (make, model, color, state, etc.) from our services. Their primary role is to identify and analyze any incorrect cases. The insights from these errors are then fed back to our engineers to directly retrain and enhance the performance of all of our AI models. Users determine when to use LPR technology, confirm matches, and undertake further actions prior to acting on the data. All actions are audited and ultimately are human verified before outputting results or using them for enforcement. Motorola Solutions conducts regular reviews of the system to ensure regulatory compliance and ìintended useî.","Our use of data for training is based entirely on user consent. When you use our service, we will ask for your permission to use your data for model improvement. If you agree (opt-in), the data from your analysis helps us enhance the accuracy of our system for identifying makes, models, states, and other features. If you do not agree, your data will not be stored or used for any training purposes.","The primary users of our detailed vehicle data are law enforcement, insurance investigators, car dealerships, and public safety agencies who need accurate information on vehicle make, model, state of origin, and identifying marks.","An error in identifying a vehicle's attributes could lead to incorrect assumptions. We mitigate this risk through high accuracy standards and human oversight. For city workers, this tool automates vehicle identification, replacing manual lookups and allowing them to focus on more critical investigative or administrative work. Users take the meaningful action of providing an audit purpose, and based on their LPR Policy, confirm proposed matches prior to enforcement. Motorola provides clear tools and user interfaces to verify the proposed matches.",Our service platform is fully accessible to people with diverse abilities. It works with common assistive technologies ensuring everyone can access their vehicle data.,"This technology is not designed to replace personnel. It's a tool to make their job easier by instantly providing detailed information like make, model, color, and state of origin, which previously required manual effort and time.","Accurate identification of make, model, state, license plate allows a city to conduct faster investigations, improve traffic management, more efficiently enforce parking regulations, and recover stolen vehicles.","Risk: Misidentifying a vehicle (e.g. wrong state, make, or misinterpreting a sticker). Mitigation: Constant model training on diverse data and a human review process for quality assurance. Risk: Misuse of detailed vehicle data for targeting individuals. Mitigation: Strict user agreements prohibiting misuse and full cooperation with law enforcement on any investigation into illegal use. Risk: Systematic errors on new license plate or vehicle designs. Mitigation: Proactive monitoring and a rapid retraining cycle to incorporate new designs as they appear",2025/07/22,2025/08/18
POL-ShotSpotter,POL,ShotSpotter,"ShotSpotter is an acoustic gunshot detection system that detects, locates, and alerts law  enforcement to gunfire incidents in near real time, enabling faster and more precise responses.","To assist law enforcement in responding rapidly to gunfire incidents, enhance victim aid, collect  forensic evidence, and improve community safety.",Urban environments or designated coverage areas where gun violence is a concern. Deployed  by law enforcement agencies to enhance public safety.,"Acoustic data of gunfire and non-gunfire impulsive sounds, collected from controlled test firings  and real-world acoustic recordings, used to train machine learning classifiers to distinguish  gunshots from other noises.",ï Detection: Acoustic sensors detect impulsive sounds. ï Classification: A machine classification algorithm analyzes the audio to identify likely  gunfire. ï Location: Time-difference-of-arrival triangulation pinpoints the location of the gunfire. ï Verification: Human acoustic experts at the Incident Review Center review and confirm  alerts. ï Notification: Verified alerts are sent to law enforcement dispatch and officer devices in  under 60 seconds.,"ï Gunfire incident metadata: time, street address, precise GPS location, number of shots,  and possible multiple shooters, drive-by, high-capacity, or full-auto gunfire. ï Audio snippets of the detected event. ï Forensic and incident analysis reports for investigative and court purposes","Optimized for fast, accurate detection and location of gunfire. Performance metrics: ï Detection and alerting time: < 60 seconds ï Location accuracy: Typically within 82 feet (25 meters) ï Detection accuracy: Detection accuracy: The ShotSpotter system is highly accurate at  detecting outdoor gunshots. From 2019-2021 the system had a 97% aggregate accuracy  rate across all of our customers, including a very small customer reported false positive  rate of less than 0.5%.","ï Sensors installed with clear acoustic line-of-sight. ï Proper network connectivity for data transmission. ï Acoustic environment without extreme interference (e.g., construction zones, gun  ranges, producing similar sounds).","(10) Conditions under which performance decreases ï Extremely loud non-gunfire impulsive noises (explosions, fireworks) can increase false  alerts (mitigated by human review). ï Severe weather conditions affecting sound propagation. ï Sensor obstruction or communications network outages.","ShotSpotter analyzes acoustic events, not people or demographics; no inherent facial, racial,  gender, or identity-based data is processed. Therefore, bias testing related to protected  characteristics is not applicable in the traditional sense.",Reports can be submitted: ï Through law enforcement agencies using ShotSpotter. ï Directly to SoundThinking via support@soundthinking.com,"ï Extensive real-world deployments in 150+ cities. ï Controlled live-fire tests in various environments (urban, suburban). ï Continuous monitoring and evaluation in various operational conditions.",SoundThinking continuously monitors system health and accuracy. Any adverse events or  significant failures are escalated and resolved in accordance with the company's service and  support protocols.,High. All alerts are verified by trained human acoustic experts at ShotSpotterís Incident Review  Center before being transmitted to law enforcement.,"Audio snippets and metadata may be used to improve ShotSpotterís proprietary classification  models, but are not shared with third-party systems.","ï Law enforcement officers and dispatchers as direct users. ï Community members indirectly affected through improved response and transparency  initiatives (e.g., ShotCast video summaries for public awareness).",ï Designed to increase public safety by improving response times to gun violence. ï Does not affect access to public services but may indirectly improve community trust in  law enforcement.,The main user interface is for trained law enforcement personnel using standard software on  MDTs or mobile devices. No public-facing UI.,ShotSpotter is not designed to replace human jobs. It augments police capabilities and  operational efficiency without eliminating positions.,"Gun violence often goes unreported (80% of incidents), leaving victims without help and  criminals unaccountable. ShotSpotter provides near real-time alerts, enabling faster responses,  saving lives, evidence collection, and reducing crime.","Risks: ï False positives or missed detections. ï Public perception and concerns surveillance. Mitigations: ï Human review of every alert to ensure accuracy. ï Transparent policies and privacy protections (e.g., The ShotSpotter system does not  retain continuous audio, only short snippets around gunfire). ï Community engagement and public reporting (e.g., ShotCast, a video summary report of  a shooting incident suitable for sharing with broadcast or other news media outlets).",2025/07/29,2025/08/18
DPH-360 Encompass 3M/Solventum,DPH,360 Encompass 3M/Solventum,"This tool addresses coding and documentation integrity by analyzing physician documentation and suggesting relevant codes. It uses natural language understanding (NLU) to identify documentation gaps and propose diagnoses or procedure codes to Health Information Services coders, aiming to maintain accuracy, quality, and productivity.","The technology is intended for use by coders, clinical documentation specialists, and analysts working in Health Information Services, as well as finance and quality teams within SFDPH.","The tool is used in coding workflows where coders either accept or reject the systemís suggested codes. This process is already in practice, and it aims to improve coding accuracy, quality, and productivity.","Solventumís AI modeling process relies on historical encounter documents and finalized codes to refine its proprietary AI, which has been deployed throughout the healthcare industry. When a new client is onboarded, existing documentation is classified, grouped, and configured, forming the primary driver of the systemís accuracy.","The 360 Encompass tool integrates with Epic to retrieve physician documentation. It uses its internal logic to annotate diagnoses or procedures, suggests coding paths for human review, and then sends final coding data back to Epic for billing.","The tool generates suggested diagnoses and procedure codes based on natural language processing. It produces these outputs each time documentation is reviewed, assisting coders or clinical documentation specialists in real time.","The tool seeks to optimize coding accuracy and productivity, ultimately improving staff satisfaction and financial stewardship. Formal accuracy metrics are to be determined through 3M data on annotation overrides or cancellations, and coders remain the final authority on code acceptance.",Documentation must be complete for the software to provide coding suggestions.,"If coders accept incorrect suggestions, the result may be claim denials or the reporting of inaccurate quality indicators. Monitoring and reviewing overrides or cancellations helps identify conditions leading to decreased accuracy.","The team compares coding outcomes between direct manual coding and autosuggestions for various populations, enabling ongoing evaluation for potential bias across different patient groups.","Any concerns about incorrect suggestions, inaccuracies, or bias can be raised during regularly scheduled business meetings, offering a consistent forum for feedback.","This technology is broadly deployed across organizations, has direct user oversight, and is continually being aligned with clinical methodologies, coding practices, and CDI.  Vendors response was ""Solventum works across the industry as an advocate for clinical methodologies, coders, and CDI to clarify areas where rules are insufficient or vague. This helps both the human user and the AI/NLP technology to produce more consistent results in line with clinical needs. Finally, the system is designed with checks and balances, to include allowing for coder notes, audit trails of usage, agreement and acceptance rates for AI/Human interaction, detailed productivity, and operational reporting, etc. This provides a system which leverages AI appropriately but ensures that adherence to best practices and regulations are consistent with industry values.""","Any concerns about incorrect suggestions, inaccuracies, or bias can be raised during regularly scheduled business meetings, offering a consistent forum for feedback.","Coders must manually accept or reject each suggestion, ensuring active human oversight. The sponsor is responsible for monitoring metrics, and Epic and 3M 360 reports are used to track performance.",DPH does not allow personally identifiable information (PII) to be retained by proprietary or third-party vendor systems.,"All patients under SFDPH may be impacted through improved documentation and coding. The primary users include coders, clinical documentation specialists, and analysts in Health Information Services, as well as finance and quality teams.","The intake form indicates that no additional patient groups or users beyond those directly involved in coding are expected to be affected. There are no identified impacts on the publicís rights, opportunities, or access.","For all SFDPH users who require assistive technologies for ADA reasons, DPH will follow standard policies and procedures for accommodation.",This technology is not expected to replace any jobs or impact the employment and/or working conditions of City workers.,"The solution affects all patients within SFDPH, improving documentation quality and enhancing coding accuracy. AI-based coding is seen as more accurate and efficient than manual approaches, potentially benefiting the organizationís financial stewardship and quality metrics.","The main risk is incorrect code acceptance, which may lead to claim denials or incorrect reporting. Coder oversight and ongoing performance monitoring help mitigate this risk.",2025/08/01,2025/08/18
